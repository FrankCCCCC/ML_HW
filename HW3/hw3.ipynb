{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "train = pd.read_csv('fashionmnist/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('fashionmnist/fashion-mnist_test.csv')\n",
    "X_train = train.iloc[:, 1:].values\n",
    "Y_train = train.iloc[:, 0].values\n",
    "X_test = test.iloc[:, 1:].values\n",
    "Y_test = test.iloc[:, 0].values\n",
    "X_train_pca = np.ones(1)\n",
    "X_test_pca = np.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Components & Training Samples\n",
    "comp_num = 400\n",
    "train_sample = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Training Samples\n",
    "def select_samples(x, y, train_sample):\n",
    "    X_out = x[:train_sample, :]\n",
    "    Y_out = y[:train_sample]\n",
    "    return X_out, Y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, X_test, Y_test):\n",
    "    model_predict = model.predict(X_test)\n",
    "    model_predict = np.array(model_predict)\n",
    "    test_set_accuracy = np.mean(Y_test == model_predict)*100\n",
    "    print(\"Test Set Accuracy: \", test_set_accuracy, \"%\")    \n",
    "\n",
    "def cross_validate(model, X_train, Y_train, cv_i):\n",
    "    cv_scores = cross_val_score(estimator=model, X=X_train, y=Y_train, cv=cv_i, n_jobs=-1)\n",
    "    cv_accuracy = np.mean(cv_scores)*100\n",
    "    print(\"CV Accuracy Scores: \", cv_scores)\n",
    "    print(\"CV Accuracy: \", cv_accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Partial Samples\n",
    "X_train, Y_train = select_samples(X_train, Y_train, train_sample)\n",
    "\n",
    "# Classifiers\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma=0.45, random_state=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "\n",
    "rnf = RandomForestClassifier(criterion='gini', n_estimators=25, random_state=1)\n",
    "\n",
    "dct = DecisionTreeClassifier(criterion='gini', max_depth=10, random_state=1)\n",
    "\n",
    "gnb = GaussianNB(priors=None)\n",
    "\n",
    "# nn_nodes = (400, 350, 300, 250, 200, 150, 100, 100, 100, 100)\n",
    "nn_nodes = (400, 500, 600, 700, 800, 700, 600, 500, 400, 200, 100, 50)\n",
    "# nn_nodes = (400, 350, 300, 250, 200, 150, 100)\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=nn_nodes, random_state=1)\n",
    "\n",
    "ovr = OneVsRestClassifier(mlp, n_jobs=-1)\n",
    "\n",
    "clfs = [('mlp', mlp), ('rnf', rnf), ('knn', knn), ('dct', dct)]\n",
    "vc = VotingClassifier(estimators=clfs, voting='soft')\n",
    "\n",
    "# bgcRnf = BaggingClassifier(base_estimator=rnf, n_estimators=3, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=-1, random_state=1)\n",
    "\n",
    "# bgcKnn = BaggingClassifier(base_estimator=knn, n_estimators=3, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=-1, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack Above Classifier into Pipeline\n",
    "\n",
    "# pipe_svm = make_pipeline(StandardScaler(), PCA(n_components=comp_num), svm)\n",
    "pipe_knn = make_pipeline(StandardScaler(), PCA(n_components=comp_num), knn)\n",
    "pipe_rnf = make_pipeline(StandardScaler(), PCA(n_components=comp_num), rnf)\n",
    "pipe_dct = make_pipeline(StandardScaler(), PCA(n_components=comp_num), dct)\n",
    "pipe_gnb = make_pipeline(StandardScaler(), PCA(n_components=comp_num), gnb)\n",
    "pipe_mlp = make_pipeline(StandardScaler(), PCA(n_components=comp_num), mlp)\n",
    "# pipe_bgcRnf = make_pipeline(StandardScaler(), PCA(n_components=comp_num), bgcRnf)\n",
    "# pipe_bgcKnn = make_pipeline(StandardScaler(), PCA(n_components=comp_num), bgcKnn)\n",
    "# pipe_ovrMlp = make_pipeline(StandardScaler(), PCA(n_components=comp_num), ovr)\n",
    "pipe_vc = make_pipeline(StandardScaler(), PCA(n_components=comp_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipe_vc\n",
    "\n",
    "# cross_validate(model, X_train, Y_train, 10)\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "test_accuracy(model, X_test, Y_test)"
   ]
  }
 ]
}